/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package parquet.generator;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.parquet.column.ParquetProperties;
import org.apache.parquet.example.data.simple.SimpleGroup;
import org.apache.parquet.hadoop.ParquetWriter;
import org.apache.parquet.hadoop.example.GroupWriteSupport;
import org.apache.parquet.hadoop.metadata.CompressionCodecName;
import org.apache.parquet.schema.MessageType;

import java.io.IOException;

public class ParquetGenerator {
    private final ParquetWriter<SimpleGroup> parquetWriter;

    public ParquetGenerator(String filePath, MessageType schema) throws IOException {
        Path hadoopPath = new Path(filePath);
        Configuration configuration = new Configuration();
        configuration.set("parquet.example.schema", schema.toString());
        GroupWriteSupport.setSchema(schema, configuration);
        GroupWriteSupport writeSupport = new GroupWriteSupport();
        parquetWriter = new ParquetWriter(hadoopPath, writeSupport, CompressionCodecName.GZIP,
                ParquetWriter.DEFAULT_BLOCK_SIZE, ParquetWriter.DEFAULT_PAGE_SIZE,
                ParquetWriter.DEFAULT_PAGE_SIZE, false, false,
                ParquetProperties.WriterVersion.PARQUET_1_0, configuration);
    }

    public void writeToFile(SimpleGroup simpleGroup) throws IOException {
        parquetWriter.write(simpleGroup);
    }

    public void closeWriter() throws IOException {
        parquetWriter.close();
    }
}
